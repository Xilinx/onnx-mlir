// RUN: onnx-mlir --EmitONNXBasic --printIR %s | FileCheck %s
<
   ir_version: 4,
   opset_import: ["" : 9]
>
test_batchnorm_op9 (float[1,1,6,2048] input) => (float[1,1,6,2048] BatchNormalization_output_Y) {
   Constant_output_0 = Constant <value: tensor = float[1] {0}> ()
   Constant_1_output_0 = Constant <value: tensor = float[1] {1}> ()
   Constant_2_output_0 = Constant <value: tensor = float[1] {1}> ()
   Constant_3_output_0 = Constant <value: tensor = float[1] {0}> ()
   BatchNormalization_output_Y, BatchNormalization_output_mean, BatchNormalization_output_var, BatchNormalization_output_saved_mean, BatchNormalization_output_saved_var = BatchNormalization <epsilon: float = 1e-05, momentum: float = 0.9> (input, Constant_2_output_0, Constant_3_output_0, Constant_output_0, Constant_1_output_0)
}

// mlir2FileCheck.py
// CHECK-LABEL:  func.func @main_graph
// CHECK-SAME:   ([[PARAM_0_:%.+]]: tensor<1x1x6x2048xf32> {onnx.name = "input"}) -> (tensor<1x1x6x2048xf32> {onnx.name = "BatchNormalization_output_Y"}) {
// CHECK-DAG:       [[VAR_0_:%.+]] = onnx.Constant dense<0.000000e+00> : tensor<1xf32>
// CHECK-DAG:       [[VAR_1_:%.+]] = onnx.Constant dense<1.000000e+00> : tensor<1xf32>
// CHECK-DAG:       [[VAR_2_:%.+]] = onnx.Constant dense<1.000000e+00> : tensor<1xf32>
// CHECK-DAG:       [[VAR_3_:%.+]] = onnx.Constant dense<0.000000e+00> : tensor<1xf32>
// CHECK:           [[Y_:%.+]], [[VAR_out_mean_:%.+]], [[VAR_out_var_:%.+]], [[VAR_saved_mean_:%.+]], [[VAR_saved_var_:%.+]] = "onnx.BatchNormalizationV9"([[PARAM_0_]], [[VAR_2_]], [[VAR_3_]], [[VAR_0_]], [[VAR_1_]]) {epsilon = 9.99999974E-6 : f32, momentum = 0.899999976 : f32} : (tensor<1x1x6x2048xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> (tensor<1x1x6x2048xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>, tensor<*xf32>)
// CHECK:           onnx.Return [[Y_]] : tensor<1x1x6x2048xf32>
// CHECK:         }
